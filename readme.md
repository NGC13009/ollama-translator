# Ollama Web Translator

这是一个浏览器插件，用于翻译网页内容。

与沉浸式翻译插件相比，它采用分段请求机制，每次仅发送少量段落至 Ollama，从而有效避免因长文本导致的超时问题，其余功能与之类似。

该插件仅支持网页翻译，不支持 PDF 等其他文件类型的翻译。

### 特色

#### 全文翻译
- **分段请求机制**：每次仅将少量段落发送至 Ollama，以避免因长文本导致的超时问题，提升响应效率。
- **无持久化缓存**：除配置文件外，不进行任何本地缓存写入（翻译完成后请勿关闭页面，否则需重新开始）。
- **临时内存缓存**：翻译过程中，可随时查看原文并对照，继续翻译时亦可记住之前的结果，避免重复翻译。
- **稳定性能表现**：系统运行流畅，基于分段请求机制，即使暂停翻译，Ollama 也能快速处理队列内容并释放显卡算力，避免因大量请求造成资源占用。
- **操作便捷性**：可以配置一个快捷键.
- **广泛兼容性**：理论上支持各类在线大模型 API（需支持非流式传输）。
- **安全隐私性**：这个插件开源并且不收集任何用户信息，确保数据传输安全。（你的配置文件可能会由浏览器提供的云同步被收集，但是翻译内容不会）
- **支持云同步**：用chrome或者edge之类的浏览器，配置应该是支持多端同步的。
- **视觉效果**：使用彩色渐变跑马灯效果来显示翻译进度和状态。

#### 分段翻译
- **侧栏翻译**：用户可以在侧栏中输入要翻译的文本段落，并点击“翻译”按钮进行翻译。
- 支持右键翻译当前段落

#### 功能

允许配置一个翻译整个页面的快捷键，需要通过浏览器设置处配置。

允许自定义以下配置项：

- **Ollama API URL**：输入 Ollama 服务的 API 地址，例如：`http://127.0.0.1:11434`。
- **模型名称**：输入模型名称，例如：`qewn3:14b`。注意：对于 `qwen3` 类模型，务必在系统提示词最后添加 `/nothink` 以关闭模型思考过程。
- **大模型采样温度系数**：值越大，生成的文本越随机。建议设置为 `0.6` 到 `1`。
- **超时时间（秒）**：设置请求超时时间，例如 `30` 秒。
- **系统提示词**：可自定义系统提示词。建议添加 `/nothink` 以提升翻译速度。
- **用户提示词模板**：使用 `{{{text}}}` 和 `{{{title}}}` 作为占位符。
- **选择器**：定义要翻译的 HTML 标签，用逗号分隔。
- **apikey**：用于在线服务时填写 API key。
- **最大同一时刻并发请求数**：控制向 Ollama 发送的请求数目，避免响应超时。
- **翻译错误颜色**：标识翻译错误时的颜色，默认为红色。

配置基于图形界面，但为便于理解，以下为相关代码片段及模型调用字段示例：

```javascript
const body = {
    model: settings.modelName,
    prompt: userPrompt,
    system: systemPrompt,
    stream: false,
    options: {
        temperature: settings.temperature
    }
};

fetch(settings.ollamaUrl,  // 调用地址，也许也能兼容openai格式
        {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${settings.apiKey}`  // 允许配置apikey
        },
        body: JSON.stringify(body),
})
```

### 注意事项
该插件请求ollama时，未指定上下文长度（`num_ctx`），一般来说默认的2048应该是足够了。如果希望指定更大上下文，请通过复写模型的`Modelfile`手动指定，或者通过ollama的环境变量进行设置。

没有在插件中指定上下文长度，是因为一些情况下，如果多个程序同时使用一个ollama服务，那么指定上下文可能导致ollama重启模型，导致性能问题。

### 使用方法

#### 插件安装
1. 打开浏览器扩展程序管理器（通常可以通过右键点击 Chrome 浏览器图标并选择“更多工具” -> “扩展程序”来打开）。
2. 在扩展程序管理器中，找到并安装这个插件。
3. 将其固定到扩展程序栏上。之后可以点击按钮来翻译页面。

#### 源码安装
支持通过源码安装，适用于 Chrome、Edge 等浏览器。  
安装步骤：  
1. 打开浏览器扩展管理页面（如 Chrome 的 `chrome://extensions/`）；  
2. 开启“开发者模式”；  
3. 点击“加载已解压的扩展程序”，选择插件源码文件夹即可完成安装。

#### 插件商店安装
🏗️ 我还没上架这个，得等等。

### 隐私问题

- 这个插件不收集任何信息。
- 关于插件的配置由浏览器存储到本地计算机。浏览器的云服务提供商可能会同步这部分配置信息（比如chrome、edge会通过登陆的账户同步多个浏览器上的插件配置）。
- 翻译内容只会发送给LLM API，例如本地的ollama，或用户自定义的`Ollama API URL`指向的服务器。插件本身不会存储或额外向其他位置任何翻译内容。
- 代码完全开源，因此用户可以审查并确认上述声明的真实性。

### 开发计划，TODO 和已经完成（或者放弃）的任务清单

- 【o】可配置翻译的选择器类型
- 【o】可设置翻译段落数目
- 【x】别弹出小窗口了，利索点，单击图标即可
- 【o】增加翻译进度提示，在弹出小页面上
- 【o】增加一个进入设置的快捷按钮
- 【o】bug：popup的计数重新打开就没了
- 【o】提示词添加页面标题，以此优化翻译质量
- 【o】翻译标题
- 【o】明显报错
- 【x】缓存
- 【o】颜色
- 【o】视觉效果
- 【o】切换原文对照（支持随时切换到翻译前的内容）
- 【o】快捷键
- 【o】配置错误检查
- 【o】动画效果
- 【o】limitless页面视觉效果
- 【o】侧栏翻译划定的内容
- 【o】性能问题：到底是啥导致的卡顿？能否共享一个动画图层？
- 【o】跳过少于n的字符（如空格、换行符等）
- 【】跳过公式
- 【】翻译时考虑上下文（打包长一些再翻译）
- 【】检查readme，所有界面是否存在写错的地方


#### 核心问题：上下文连续性

目前的插件是将文本拆分成段落送入LLM的，这导致一些带有公式或者格式的文本会被拆分。例如

```html
<p>这段话包含<b>加粗</b>的文本</p>
<p>对于<math>x<span>复杂的数学表达式latex源代码</span></math>求导得到<math>y<span>复杂的数学表达式latex源代码</span></math>之后，有....</p>
```

会被拆分成
```json
[
    "这段话包含",
    "加粗",
    "的文本",
    "对于",
    "x",
    "求导得到:",
    "y",
    "之后，有...."
]
```

显然将他们分别传入LLM效果会很差。

一个可行的思路是将比较少的子节点直接按HTML送入LLM，超过一定长度则进行占位符替换，例如对于刚才的例子，应该是

```json
[
    "这段话包含<b>加粗</b>的文本",
    "对于 @1# 求导得到 @2# 之后，有....",
]
```

如此，LLM翻译就得到了完整的上下文，只需要翻译完成后替换回来。

然而，有时候占位符顺序会因为语言的不同而改变位置。此时就需要改变html结构了。然而js并不能轻松支持这个操作。

同时，由于请求是异步的，因此假如子结构包含需要翻译的内容，那么还需要保证”指针“的有效性。

